{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_WI0wMcC0V9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Flatten,Dense,MaxPooling2D,Conv2D,BatchNormalization,Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8klY9OgVGsm1",
        "outputId": "add3831f-a19a-4d45-d003-ab433c2b5337"
      },
      "outputs": [],
      "source": [
        "file_format = ('.jpg','.jpeg','.png')\n",
        "\n",
        "def corrupt_check(dir):\n",
        "  count=0\n",
        "  for root,_,files in os.walk(dir):\n",
        "      for file in files:\n",
        "          if file.endswith(file_format):\n",
        "              try:\n",
        "                img=Image.open(os.path.join(root,file))\n",
        "                img.verify()\n",
        "                #print(f\"file path{os.path.join(root,file)}\")\n",
        "                count +=1\n",
        "              except:\n",
        "                print(f\"corrrupt file path{os.path.join(root,file)}\")\n",
        "                #os.remove(os.path.join(root,file))\n",
        "          else:\n",
        "              print(f\"unsupported file {os.path.join(root,file)}\")\n",
        "  print(count)\n",
        "\n",
        "file_path_train='G:/aman office/practise/face_emotion_detection/train'\n",
        "corrupt_check(file_path_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-lUN_-vifC8",
        "outputId": "595dde7a-a5e8-4367-c17c-ee29b6f4ef3f"
      },
      "outputs": [],
      "source": [
        "file_format = ('.jpg','.jpeg','.png')\n",
        "\n",
        "def corrupt_check(dir):\n",
        "  count=0\n",
        "  for root,_,files in os.walk(dir):\n",
        "      for file in files:\n",
        "          if file.endswith(file_format):\n",
        "              try:\n",
        "                img=Image.open(os.path.join(root,file))\n",
        "                img.verify()\n",
        "                #print(f\"file path{os.path.join(root,file)}\")\n",
        "                count +=1\n",
        "              except:\n",
        "                print(f\"corrrupt file path{os.path.join(root,file)}\")\n",
        "                #os.remove(os.path.join(root,file))\n",
        "          else:\n",
        "              print(f\"unsupported file {os.path.join(root,file)}\")\n",
        "  print(count)\n",
        "\n",
        "file_path_test='G:/aman office/practise/face_emotion_detection/test'\n",
        "corrupt_check(file_path_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s288ENRNaFjC"
      },
      "outputs": [],
      "source": [
        "train_dir = file_path_train\n",
        "validation_dir = file_path_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIcJCV5YaLZX"
      },
      "outputs": [],
      "source": [
        "# Image Data Generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KCPuBcSam3d",
        "outputId": "3aa7a4db-e037-4195-e825-ad93574f1ec3"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale'  \n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale' \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJacxRNgF5iv",
        "outputId": "25c44f31-2bcd-4af0-a3cc-ad9f42a27b00"
      },
      "outputs": [],
      "source": [
        "# 3. CNN Model \n",
        "model = Sequential([\n",
        "    Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMaKgqV8HPGd"
      },
      "outputs": [],
      "source": [
        "num_classes = len(train_generator.class_indices) \n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)),  \n",
        "    MaxPooling2D(2,2),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "scnLN7FLOsuW",
        "outputId": "9916d518-c7e1-40dd-e324-cdf278c62bcf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1VKCCbDPQ8f",
        "outputId": "a878b7f7-44f7-49aa-c4ef-825a70f4962f"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Model Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping, lr_scheduler]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"best_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "wSSLIC77wxMk",
        "outputId": "b6fbd985-cbe9-4d8a-c9f5-dd7147351d32"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('G:/aman office/practise/face_emotion_detection/face_emotion_detection.h5')\n",
        "\n",
        "val_images, val_labels = next(validation_generator)\n",
        "predictions = model.predict(val_images)\n",
        "y_true = np.argmax(val_labels, axis=1)\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
